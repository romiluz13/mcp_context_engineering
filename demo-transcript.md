The honeymoon phase for vibe coding is over and the new paradigm for AI coding is context engineering. I truly believe this is going to be the next big thing for AI as a whole. And let me show you why. So starting off earlier this year, Andre Karpathy coined the term vibe coding. It's all about relying 100% on your AI coding assistant to build applications for you with barely any input and no validation. And this concept completely blew up. We all fell for this trap because of the dopamine hit of instant code generation and also because vibe coding is great for weekend hacks and prototypes. Basically, you rely on intuition and repetition until your code seemingly works. At least until you try to productionize and scale it, and then suddenly it doesn't. And you can read these statistics all over the internet. One article that I appreciate in particular is the state of AI code quality from Kodo. They did a massive survey across the developer landscape. You can see in the bottom purple quadrant here, 76.4% of real developers have low confidence shipping AI code without human review, and they encounter a lot of hallucinations. And it's not like AI coding itself is bad, I mean I love it myself. It's vibe coding, AI code without human review that is the problem. Because here's the thing, intuition does not scale. Structure does. I heard that recently. I thought it was so beautifully put. Because the biggest problem that we have with AI coding assistance right now is around context. Often times they miss or lack it entirely, so they don't have the necessary context to get the job done. We need better context, we need structure. That is where context engineering comes in. So let's kick things off right now by diving into what context engineering is. Then after, we'll get into the lab with Claude Code. I'll show you how it works for real, with a practical example that you can use as a template to instantly improve your AI coding. This is not theoretical. For some reason, YouTube has been obsessed with the Gemini CLI recently. Meanwhile, context engineering has been blowing up everywhere else on the internet and context engineering is definitely a lot more important. Like I always say, capabilities over tools. The Gemini CLI is a tool. Context engineering is a very important capability that should really dictate the way that you work with AI as a whole. And context engineering was even condoned by Andre, who originally coined vibe coding. This is his response to a tweet from Toby, the CEO of Shopify, where he's comparing context engineering to prompt engineering. We'll talk about that in a second, but I really love his definition here. It is the art of providing all the context for the task to be plausibly solvable by the LLM. Here's the paradigm shift with this. Context, which is our instructions, and rules, documentation, so on, that deserves the respect to be treated as an engineered resource, requiring careful architecture, just like everything else in software. When AI coding assistants fail, it's most often because they just don't have the information they need. And no, I'm not just talking about prompt engineering. Context engineering is very much a step up like Toby is saying. Prompt engineering is all about tweaking wording, phrasing things in a specific way to get a single good answer from the LLM. But context engineering, supplying all relevant facts, rules, documents, plans, tools. So the LLM has a whole ecosystem of context. That is the paradigm shift from basic prompting and vibe coding. Prompting is just one piece of the bigger picture that we have here. And one last thing in X. I thought this was really funny. The top comment from Andre's reply to Toby is saying context engineering is the new vibe coding. And then Andre replied by saying he's not trying to coin a new word or something. But Andre, if you're watching this, I think it is too late. I'm sorry. There is a reason that people hang on to every word that you say. Thank you for everything that you do in the AI space. But anyway, if you are a visual learner, I also found this beautiful diagram in GitHub on context engineering. So all the different components that we have in here together make up what context engineering is. So we have prompt engineering as a part of it, like we already talked about. We have structured output. It's a way to make the output of AI agents and coding assistants more reliable. We have state, history, and memory. So agents and coding assistants being able to remember what they built in the past. We can do things like provide examples. And then also RAG is a huge component of context engineering. Not something that I'm going to be focusing on a ton in this video. But that's actually because I have a lot more coming soon for you for RAG and context engineering. Being able to supply external documentation and knowledge to our AI coding assistant. And I will say, there is a lot that is going on here. If you want to really do context engineering well, you have to put a lot of time up front, creating this context for your AI coding assistant. It's a lot different than vibe coding, where you generally dive right into the actual coding. But I always love to quote Abraham Lincoln here. He said, if you give me six hours to chop down a tree and I will spend the first four sharpening the axe. And that is exactly what we are doing here. And it is well worth your time to invest up front into creating this context, because you're going to get infinitely better results versus diving straight into the implementation. You're going to have better code, you're going to actually save a lot of time in the end, and then just not have to go through as much pain. That is the whole point. That is what I want to show you in action in a little bit here. And the very last article that I want to show you is the rise of context engineering from LangChain. This is definitely worth a read. So I'll link to this in the description of the video. And actually everything that I shared with you here, I'll link in the description. I've definitely been doing a deep dive into context engineering. I hope that's very obvious to you. And so their definition of context engineering is pretty cool because it aligns very, very closely with what we've seen already. But this is the key paragraph that I want to focus on here. LLM applications are evolving from single prompts to more complex, dynamic agentic systems. And such, context engineering is becoming the most important skill an AI engineer can develop. That is a bold claim. Maybe it's a bit of an exaggeration. I don't really know if it's the most important skill. But yeah, this just shows the theme that's starting to emerge here where context engineering certainly feels like the thing to focus on right now. And so with that, let's now dive into Claude Code. I'll show you how we can implement this for real, to get some insane results with AI coding assistance. So here is my template for you, and a GitHub repository that I'll have linked in the description. My introduction to context engineering. Now, you can get very, very deep with context engineering. Diving into RAG and memory, things that I'll cover a lot more in the near future here. What I want to do with this is introduce you to the idea of using AI coding assistance to create a super comprehensive plan for a new project, and then implement that. And we're going to be using Claude Code. This is going to work for really any AI coding assistant, but I'm focusing on Claude Code here because it is the most agentic and widely considered the most powerful AI coding assistant right now. And we're going to use Claude Code to plan, create the tasks, code, write tests, and iterate on that. All end to end, so that after just a few prompts, we have a full project implemented for us. That is the power that we have with context engineering. And by the way, a lot of what I'm about to dive into with you here is inspired by someone in the Dynamis community, Rasmus. He did a workshop last month in our community, and it was an absolute killer. So awesome. He covered his agentic coding process, focusing a lot on Claude Code. He did a lot of things related to context engineering, and he actually open sourced a lot of the resources that he shared with us in the workshop. So I'll link to this in the description as well. So, credit where credit is due, Rasmus has inspired a lot of my ideas. And also, if you want to dive a lot more into building AI agents, using AI coding assistants, things like context engineering, definitely check out Dynamis.ai. It is the place to be where constantly pushing the limit of what's possible with workshops like this. And so with that, back into my template that I have for you. In the README here, I have a quick start. You can follow along with this in just like 10 minutes and level up your AI coding game that fast with context engineering. But then also, I have this repo cloned locally. I'm just going to walk you through exactly what we're doing here, and then we'll see a demo in action. Now, before we move on, I just want to mention really quickly that there are definitely a lot of security risks when using AI coding assistants that are super important for you to keep in mind. It doesn't matter if you're using Claude Code or Windswept or something else like GitHub Copilot. These risks crop up that you might not even be aware of. Things like prompt injection, model poisoning, data leakage, these aren't theoretical threats anymore. That is why Snyk, a company that is trusted for securing AI generated code, is hosting a free live webinar Tuesday, July 15th at 11:00 AM Eastern time, covering the OWASP Top 10 for LLMs. This is an event that you don't want to miss. A clear breakdown of these critical vulnerabilities. You get to see live defenses against these attacks, like model poisoning and prompt injection, and learn best practices for avoiding these security issues with AI code. Vandana Verma Segel from Snyk is going to be walking us through best practices for handling AI-generated code and showing us real world examples that you can apply immediately. Plus, if you are an ISC2 member, you get one CPE credit just for attending. It doesn't matter where you're at with your technical ability. If you are using AI coding assistants, you have to understand these risks. So, I have a link in the description to register. Again, this is Tuesday, July 15th at 11:00 AM Eastern, and I'm definitely going to be there myself. So I have the repo cloned locally. Now let's dive into creating a super comprehensive plan for a new project and implementing it end-to-end with Claude Code. And like I said, context engineering can be decently involved up front. So there are quite a few different files that I want to cover here. Markdown files for all the instructions, the different parts of our context. And so the first file that I want to cover is our claude.md. These are the global rules for our AI coding assistant, similar to, you know, Windswept rules or Cursor rules if you've used those AI IDs before. I've covered my strategy for global rules and a template for you in a video I'll link in the top right. This is the highest level information that we want to give to our AI coding assistant. Things like best practices that we want it to follow. The way that we want it to write tests for our project. Um, the way that we want it to manage tasks, the style and convention guides, like all of this high-level information, we want to put in claude.md. And then going back to the README here, the next file that I want to cover is our initial.md. This is where we describe the feature that we want implemented by Claude Code or your AI coding assistant. So something like, I want to build an AI agent that does ABC, built with XYZ. And it's worth being pretty detailed in this section. And then second, it's so, so important, whenever you can, provide examples to the AI coding assistant. This just helps so much. And so this could be from past projects that you've worked on, that have some similar implementations for what we want to build now. It could be code examples or snippets that you found online. You just want to put that in this examples folder. And so, I have this in the repo specifically to call out, like, this is your place to add examples for your AI coding assistant. And then also, getting into the RAG part of context engineering, we have documentation. So listing out any online docs that you want the AI coding assistant to reference, or any MCP servers for RAG that you want it to use, like my Crawl for AI RAG, for example. I'm not going to be focusing on this too much right now, but it still is a very crucial part of context engineering. And then last but not least, a place for any other kinds of considerations that you have for your AI coding assistant. And this is a really good place to include any gotchas, things that AI coding assistants mess up on a lot in your experience. Just specifying how to avoid that right here. And so what I'm going to do for this build, because I am going to show you a full example here, is I'm actually going to delete initial.md. And I'm going to rename the example that I have in the repo, because we're going to use this to build out an AI agent here. And so going to initial.md. I'm building an AI agent with Pydantic AI. I have some examples that I'll add into the folder off camera. For the documentation, I'm just going to have it reference Pydantic AI. And usually, I'd want to use an MCP server for RAG, but I'm just keeping it simple here. Um, and then just for some other considerations here, some things that I have it mess up on quite a bit is the use of environment variables. Um, telling it to make sure that it has the project structure in README. So just little things like that, just a couple of examples that I wanted to give here. So, that is my initial.md. And so now going back to the README, we have our global rule setup. We have our initial prompt. Now it is time to generate a full plan for our implementation. And this is where we get into two of my favorite things for context engineering. Claude Code slash commands, and PRPs, which is short for product requirements prompts. And so, they're similar to product requirements documents, PRDs. You've probably heard of this before if you've been diving into AI coding. But they are specifically designed to instruct an AI coding assistant. So we're not creating like an architecture document, we're actually creating a prompt that we're going to run with Claude Code. So we use Claude Code to build a prompt, which is part of the project plan. And then we use that to actually do the implementation end to end. It's so, so powerful. And we're using slash commands to take care of this, so we don't have to prompt a lot of things from scratch. Every time we're using this process to begin a project. And so in the dot claude folder, if you have a folder called commands, any of the markdown files that you have here can be executed as custom commands for Claude Code. It is a beautiful thing. And so our first command here is generate PRP. This is a prompt to create a very comprehensive plan as another prompt for Claude Code. So it is a multi-step process here. We're getting a little bit more involved here now with context engineering. And so, I'm not going to go through the details of this entire document, but we're walking it through what it looks like to take in a feature requirement. So we're going to actually pass in initial.md. And then do a bunch of research on our behalf, some architectural planning. We're having it really think through the problem step by step here to create a comprehensive plan for implementation. This is the engineered context that I'm really getting at with context engineering. And so, the way this works, and I'm going to go into my terminal here, and I'm going to open up Claude. When we have our commands within the commands folder. Now I can do slash generate-PRP. And then the argument that I want to pass in here, this is just anything that I enter after a space, this is what's going to be given and it's going to replace the arguments placeholder here. So if I say initial.md, I'm now telling this command that the feature file is going to be initial.md. So now Claude Code is going to look at initial.md, use that to guide the feature that it is then going to plan. So I'm going to go ahead and run this right now. And this will take a good amount of time, because Claude Code really goes through this in a comprehensive way. Making sure that it generates a complete PRP for us. And by the way, it is also using a PRP template that I have available in the PRPs folder. So this is kind of its starting point. This is the template that it bases the whole document off of that it produces after we are done with this command. And so I'm going to pause and come back once it's generated the PRP. Then we'll take a look at what that looks like and use it to build our project. All right, so I'm coming back just for a second here to show you the process in action. The thing that I love about using PRPs and just context engineering in general, is watching these relatively large to-do lists that it builds autonomously and knocks out one at a time. And so what it's doing is researching different APIs on my behalf to really make sure that the PRP we generate for implementation has all the details necessary to not hallucinate the usage of APIs. And that's one of the biggest things that AI coding assistants mess up on a lot. And so it's doing research, analyzing the existing codebase and then the examples that we're giving it, reviewing documentation for Pydantic AI, creating the PRP based on that, writing it all and then it is done. There's so much that it's taking care of here. Not just creating one markdown file, but all of the research and planning that it does beforehand. And so yeah, now I will come back once it is complete. And there we go. After more than 30 minutes, Claude Code has completed and tested our agent end to end. That is the power of agentic coding with Claude Code and context engineering. And it did take quite a few tokens to do this, to say the least. And so I'll have a screenshot right here of the token usage in the middle of the development towards the end. But I'm not bringing my own API key. I'm taking advantage of the Max plan for Claude. And so I didn't have to pay anything more for it to do all this work for me. It is a beautiful thing. And so, yeah, this is the output here at the end, describing what it did for us. There is one bit of iterating that I had to do here. There was some weirdness for how the tools were set up for the agent, like, it was creating these functions as dependencies for the agent, which isn't really how you're supposed to do it with Pydantic AI. So, I did one round of iterating, but that was it. And everything is working really, really well. And so I do, like I just did, I highly recommend not vibe coding, actually validating the output. But if you validate the output, have your context engineering set up, you are set. And so, yeah, we can go into the terminal here. I can run PyTest so we can see all of the tests that it created and used to iterate on our agent. Everything is passing, just a couple of warnings that we can ignore. And then also, we can run our CLI. So I followed the instructions that it created in the README for me to set things up. And I implemented my environment variables. And so now I can run Python CLI.py. We're connected to our agent, running GPT 4.1 Mini for our model. You can really use any model that you want. Actually, one of the things that I had in my examples was showing how to make us you can set up different providers for your Pydantic AI agent, like Gemini, or Ollama, or OpenAI. So we can actually do that as well. It's really cool. And so then here I can just say, hello. We can test a basic message to our agent. Looking really good. We got our output here. Our terminal is looking really beautiful. And I can say something like, search the web for the latest on Claude Code. So we can have it use the web search tool because that's our research agent. I'm not going to test to sell out a ton right here. I'm just showing you right now that like, everything is working. We're using the Brave API. We're using the OpenAI API. We got some results here. It's going to spit out a response for us in a second. It's just doing a lot of web searching for us, I guess. And there we go. All right. We got our response from our agent. So this is working really, really well. Like I said, I just had to iterate once. So I just kicked off this build and I set up all the permissions ahead of time. So I just went and, you know, took my dog out a walk, came back and the agent was done. And that's what I'm showing you guys right here. So really, really cool. That is the power of context engineering. And this is just getting your feet wet. I very much encourage you to use this template that I have for you. Dive into creating these comprehensive plans and using them with an AI coding assistant like Claude Code. And then just take it from there. There's so much more you can do with context engineering with memory and state and RAG. A lot of things that I want to cover soon on my channel as well. So you can really go down the rabbit hole of context engineering. And like we talked about at the start of this video, it is really the thing to focus on right now. And so dive deep, have fun with it. I hope this helps as a starting point for you as well. And so if you appreciate this video, and you're looking forward to more things AI coding, AI agents and context engineering. Definitely give me a like and a subscribe. And with that, I will see you in the next video.